// Copyright 2021 Adam Chalkley
//
// https://github.com/atc0005/check-vmware
//
// Licensed under the MIT License. See LICENSE file in the project root for
// full license information.

package main

import (
	"context"
	"errors"
	"fmt"
	"strings"

	"github.com/atc0005/go-nagios"
	"github.com/vmware/govmomi/vim25/mo"

	"github.com/atc0005/check-vmware/internal/config"
	"github.com/atc0005/check-vmware/internal/vsphere"

	zlog "github.com/rs/zerolog/log"
)

//go:generate go-winres make --product-version=git-tag --file-version=git-tag

func main() {

	plugin := nagios.NewPlugin()

	// defer this from the start so it is the last deferred function to run
	defer plugin.ReturnCheckResults()

	// Annotate all errors (if any) with remediation advice just before ending
	// plugin execution.
	defer vsphere.AnnotateError(plugin)

	// Setup configuration by parsing user-provided flags. Note plugin type so
	// that only applicable CLI flags are exposed and any plugin-specific
	// settings are applied.
	cfg, cfgErr := config.New(config.PluginType{DiskConsolidation: true})
	switch {
	case errors.Is(cfgErr, config.ErrVersionRequested):
		fmt.Println(config.Version())

		return

	case cfgErr != nil:
		// We're using the standalone Err function from rs/zerolog/log as we
		// do not have a working configuration.
		zlog.Err(cfgErr).Msg("Error initializing application")
		plugin.ServiceOutput = fmt.Sprintf(
			"%s: Error initializing application",
			nagios.StateUNKNOWNLabel,
		)
		plugin.AddError(cfgErr)
		plugin.ExitStatusCode = nagios.StateUNKNOWNExitCode

		return
	}

	// Enable library-level logging if debug or greater logging level is
	// enabled app-wide.
	handleLibraryLogging()

	// Set context deadline equal to user-specified timeout value for plugin
	// runtime/execution.
	ctx, cancel := context.WithTimeout(context.Background(), cfg.Timeout())
	defer cancel()

	// Record thresholds for use as Nagios "Long Service Output" content. This
	// content is shown in the detailed web UI and in notifications generated
	// by Nagios.
	plugin.CriticalThreshold = "Disk consolidation needed for one or more Virtual Machines."

	plugin.WarningThreshold = config.ThresholdNotUsed

	if cfg.EmitBranding {
		// If enabled, show application details at end of notification
		plugin.BrandingCallback = config.Branding("Notification generated by ")
	}

	log := cfg.Log.With().
		Str("included_resource_pools", cfg.IncludedResourcePools.String()).
		Str("excluded_resource_pools", cfg.ExcludedResourcePools.String()).
		Str("ignored_vms", cfg.IgnoredVMs.String()).
		Logger()

	log.Debug().Msg("Logging into vSphere environment")
	c, loginErr := vsphere.Login(
		ctx, cfg.Server, cfg.Port, cfg.TrustCert,
		cfg.Username, cfg.Domain, cfg.Password,
		cfg.UserAgent(),
	)
	if loginErr != nil {
		log.Error().Err(loginErr).Msgf("error logging into %s", cfg.Server)

		plugin.AddError(loginErr)
		plugin.ServiceOutput = fmt.Sprintf(
			"%s: Error logging into %q",
			nagios.StateCRITICALLabel,
			cfg.Server,
		)
		plugin.ExitStatusCode = nagios.StateCRITICALExitCode

		return
	}
	log.Debug().Msg("Successfully logged into vSphere environment")

	defer func() {
		if err := c.Logout(ctx); err != nil {
			log.Error().
				Err(err).
				Msg("failed to logout")
		}
	}()

	log.Debug().Msg("Performing initial filtering of vms")
	vmsFilterOptions := vsphere.VMsFilterOptions{
		ResourcePoolsIncluded:       cfg.IncludedResourcePools,
		ResourcePoolsExcluded:       cfg.ExcludedResourcePools,
		FoldersIncluded:             cfg.IncludedFolders,
		FoldersExcluded:             cfg.ExcludedFolders,
		VirtualMachineNamesExcluded: cfg.IgnoredVMs,

		// NOTE: This plugin is hard-coded to evaluate powered off and powered
		// on VMs equally. I'm not sure whether ignoring powered off VMs by
		// default makes sense for this particular plugin.
		//
		// Please share your feedback here if you feel differently:
		// https://github.com/atc0005/check-vmware/discussions/176
		//
		// Please expand on some use cases for ignoring powered off VMs by
		// default.
		// IncludePoweredOff:           cfg.PoweredOff,
		IncludePoweredOff: true,
	}
	vmsFilterResults, vmsFilterErr := vsphere.FilterVMs(
		ctx,
		c.Client,
		vmsFilterOptions,
	)
	if vmsFilterErr != nil {
		log.Error().Err(vmsFilterErr).Msg(
			"error filtering VMs",
		)

		plugin.AddError(vmsFilterErr)
		plugin.ServiceOutput = fmt.Sprintf(
			"%s: Error filtering VMs",
			nagios.StateCRITICALLabel,
		)
		plugin.ExitStatusCode = nagios.StateCRITICALExitCode

		return
	}
	log.Debug().Msg("Finished initial filtering of vms")

	// here we diverge from other plugins

	// State reload/refresh operation for remaining VMs is potentially
	// expensive, so only perform this step if requested.
	switch {
	case cfg.TriggerReloadStateData:
		log.Debug().
			Bool("trigger_state_reload", cfg.TriggerReloadStateData).
			Msg("Triggering reload of each VirtualMachine to ensure fresh metadata")
		vmEntityVals := make([]mo.ManagedEntity, 0, vmsFilterResults.NumVMsAfterFiltering())
		for _, vm := range vmsFilterResults.VMsAfterFiltering() {
			vmEntityVals = append(vmEntityVals, vm.ManagedEntity)
		}
		if err := vsphere.TriggerEntityStateReload(ctx, c.Client, vmEntityVals...); err != nil {
			log.Error().Err(err).Msg(
				"error triggering state reload for VMs",
			)

			plugin.AddError(err)
			plugin.ServiceOutput = fmt.Sprintf(
				"%s: Error triggering state reload for VMs",
				nagios.StateCRITICALLabel,
			)
			plugin.ExitStatusCode = nagios.StateCRITICALExitCode

			return
		}

	default:
		log.Debug().
			Bool("trigger_state_reload", cfg.TriggerReloadStateData).
			Msg("Trigger reload flag not specified, skipping reload/refresh of VirtualMachine state data")

	}

	log.Debug().Msg("Filter VMs to those needing disk consolidation")
	// Create a new collection of VMs with just those found to require disk
	// consolidation. Keep filteredVMs collection as-is; we'll use that as our
	// "baseline" against the list of VMs found requiring disk consolidation.
	vmsNeedingConsolidation, numVMsExcludedByConsolidationState := vsphere.FilterVMsByDiskConsolidationState(vmsFilterResults.VMsAfterFiltering())
	numVMsRequiringDiskConsolidation := len(vmsNeedingConsolidation)

	log.Debug().
		Str("vms_filtered_by_disk_consolidation_status", strings.Join(vsphere.VMNames(vmsNeedingConsolidation), ", ")).
		Int("vms_needing_consolidation", numVMsRequiringDiskConsolidation).
		Int("vms_excluded_by_consolidation_state", numVMsExcludedByConsolidationState).
		Msg("VMs after disk consolidation needed filtering")

	log.Debug().Msg("Compiling Performance Data details")

	pd := append(
		vsphere.VMFilterResultsPerfData(vmsFilterResults),
		[]nagios.PerformanceData{
			// The `time` (runtime) metric is appended at plugin exit, so do not
			// duplicate it here.
			{
				Label: "vms_with_consolidation_need",
				Value: fmt.Sprintf("%d", numVMsRequiringDiskConsolidation),
			},
			{
				Label: "vms_without_consolidation_need",
				Value: fmt.Sprintf("%d", numVMsExcludedByConsolidationState),
			},
		}...,
	)

	if err := plugin.AddPerfData(false, pd...); err != nil {
		log.Error().
			Err(err).
			Msg("failed to add performance data")

		// Surface the error in plugin output.
		plugin.AddError(err)

		plugin.ExitStatusCode = nagios.StateUNKNOWNExitCode
		plugin.ServiceOutput = fmt.Sprintf(
			"%s: Failed to process performance data metrics",
			nagios.StateUNKNOWNLabel,
		)

		return
	}

	// Update logger with new performance data related fields
	log = log.With().
		Int("resource_pools_evaluated", vmsFilterResults.NumRPsAfterFiltering()).
		Int("vms_total", vmsFilterResults.NumVMsAll()).
		Int("vms_after_filtering", vmsFilterResults.NumVMsAfterFiltering()).
		Int("vms_excluded_by_name", vmsFilterResults.NumVMsExcludedByName()).
		Int("vms_excluded_by_power_state", vmsFilterResults.NumVMsExcludedByPowerState()).
		Int("vms_with_consolidation_need", numVMsRequiringDiskConsolidation).
		Int("vms_without_consolidation_need", numVMsExcludedByConsolidationState).
		Logger()

	switch {
	case numVMsRequiringDiskConsolidation > 0:

		// *ANY* VMs requiring disk consolidation results in a CRITICAL state.

		vmsList := strings.Join(vsphere.VMNames(vmsNeedingConsolidation), ", ")

		log.Error().
			Str("virtual_machines", vmsList).
			Msg("Virtual Machines found in need of disk consolidation")

		plugin.AddError(vsphere.ErrVirtualMachineDiskConsolidationNeeded)

		plugin.ServiceOutput = vsphere.VMDiskConsolidationOneLineCheckSummary(
			nagios.StateCRITICALLabel,
			vmsFilterResults,
			vmsNeedingConsolidation,
		)

		plugin.LongServiceOutput = vsphere.VMDiskConsolidationReport(
			c.Client,
			vmsFilterOptions,
			vmsFilterResults,
			vmsNeedingConsolidation,
		)

		plugin.ExitStatusCode = nagios.StateCRITICALExitCode

		return

	default:

		// success path

		log.Debug().Msg("VirtualMachine disk consolidation not needed")

		plugin.ServiceOutput = vsphere.VMDiskConsolidationOneLineCheckSummary(
			nagios.StateOKLabel,
			vmsFilterResults,
			vmsNeedingConsolidation,
		)

		plugin.LongServiceOutput = vsphere.VMDiskConsolidationReport(
			c.Client,
			vmsFilterOptions,
			vmsFilterResults,
			vmsNeedingConsolidation,
		)

		plugin.ExitStatusCode = nagios.StateOKExitCode

		return
	}

}
